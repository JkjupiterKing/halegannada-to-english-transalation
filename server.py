import sys
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
import pickle
import os
import google.generativeai as genai
import openai # Added for DeepSeek
import traceback
import time
import json
import base64
from PIL import Image
from io import BytesIO
import random
import numpy as np
import tensorflow as tf
from keras.models import load_model
from keras.preprocessing.sequence import pad_sequences

app = Flask(__name__)
CORS(app)

# --- Seq2Seq Model Loading ---
SEQ2SEQ_MODEL_PATH = 'assets/seq2seq_model.h5'
INPUT_TOKENIZER_PATH = 'assets/input_tokenizer.pkl'
TARGET_TOKENIZER_PATH = 'assets/target_tokenizer.pkl'

seq2seq_model = None
input_tokenizer = None
target_tokenizer = None
max_input_len = 200 # Should match the model's training configuration

try:
    if os.path.exists(SEQ2SEQ_MODEL_PATH):
        seq2seq_model = load_model(SEQ2SEQ_MODEL_PATH)
        print("Successfully loaded Seq2Seq model.")
    else:
        print(f"Warning: Seq2Seq model not found at {SEQ2SEQ_MODEL_PATH}")

    if os.path.exists(INPUT_TOKENIZER_PATH):
        with open(INPUT_TOKENIZER_PATH, 'rb') as f:
            input_tokenizer = pickle.load(f)
        print("Successfully loaded input tokenizer.")
    else:
        print(f"Warning: Input tokenizer not found at {INPUT_TOKENIZER_PATH}")

    if os.path.exists(TARGET_TOKENIZER_PATH):
        with open(TARGET_TOKENIZER_PATH, 'rb') as f:
            target_tokenizer = pickle.load(f)
        print("Successfully loaded target tokenizer.")
    else:
        print(f"Warning: Target tokenizer not found at {TARGET_TOKENIZER_PATH}")

except Exception as e:
    print(f"Error loading Seq2Seq model or tokenizers: {str(e)}")
    traceback.print_exc()
    seq2seq_model = None # Ensure model is None if loading fails

# Configure Gemini API
GEMINI_API_KEY = "AIzaSyCAnmyjkM6tvLpgP-iYk5hnIHKpj6mZba0"
genai.configure(api_key=GEMINI_API_KEY)

# Configure DeepSeek API via OpenRouter
DEEPSEEK_API_KEY = "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" # This is an OpenRouter key
deepseek_client = openai.OpenAI(api_key=DEEPSEEK_API_KEY, base_url="https://openrouter.ai/api/v1")

# Rate limiting and retry configuration
MAX_RETRIES = 5
INITIAL_RETRY_DELAY = 10  # seconds
MAX_RETRY_DELAY = 120    # seconds

def exponential_backoff(attempt):
    """Calculate delay with exponential backoff and jitter"""
    delay = min(MAX_RETRY_DELAY, INITIAL_RETRY_DELAY * (2 ** attempt))
    jitter = random.uniform(0, 0.1 * delay)  # 10% jitter
    return delay + jitter

def retry_with_backoff(func, *args, **kwargs):
    """Retry function with exponential backoff"""
    last_exception = None
    
    for attempt in range(MAX_RETRIES):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            last_exception = e
            
            # Check if it's a quota error (common for HTTP 429)
            # For DeepSeek/OpenAI, APIError often includes status codes
            status_code = getattr(e, 'status_code', None)
            if "429" in str(e) or "quota" in str(e).lower() or status_code == 429:
                if attempt < MAX_RETRIES - 1:
                    delay = exponential_backoff(attempt)
                    print(f"Rate limit hit or temporary API error. Retrying in {delay:.2f} seconds... (Attempt {attempt + 1}/{MAX_RETRIES})")
                    time.sleep(delay)
                else:
                    print(f"Max retries reached for rate limit error: {str(e)}")
                continue # Continue to next attempt or exit loop if max retries reached
            else:
                # If it's not a known retryable error, raise immediately
                print(f"Non-retryable API error: {str(e)}")
                raise e
    
    raise Exception(f"Max retries ({MAX_RETRIES}) exceeded. Last error: {str(last_exception)}")

# Initialize the Gemini model - using the latest pro model that supports vision
try:
    gemini_model = genai.GenerativeModel('gemini-1.5-pro-latest') # Renamed to gemini_model for clarity
    print("Successfully initialized Gemini model")
except Exception as e:
    print(f"Error initializing Gemini model: {str(e)}")
    traceback.print_exc()
    gemini_model = None # Ensure it's None if init fails

def process_image(image_data):
    """Process image data: extract Halegannada text using Gemini, then translate using DeepSeek."""
    try:
        print("\n=== Starting Image Processing ===")
        print("Step 1: Checking image data...")
        
        if not image_data:
            print("Error: No image data received")
            return "Error: No image data received"
            
        try:
            if isinstance(image_data, str):
                if image_data.startswith('data:image'):
                    print("Converting base64 to bytes...")
                    try:
                        base64_data = image_data.split(',')[1]
                        image_bytes = base64.b64decode(base64_data)
                        print("Base64 conversion successful")
                    except Exception as e:
                        print(f"Base64 decode error: {str(e)}")
                        return f"Error decoding image: {str(e)}"
                else:
                    print("Error: Invalid image data format")
                    return "Error: Invalid image data format"
            else:
                image_bytes = image_data # Assuming it's already bytes
                
            print("Step 2: Opening image...")
            try:
                image = Image.open(BytesIO(image_bytes))
                print(f"Image opened successfully. Format: {image.format}, Size: {image.size}, Mode: {image.mode}")
            except Exception as e:
                print(f"Error opening image: {str(e)}")
                return f"Error opening image: {str(e)}"
            
            print("Step 3: Converting image format...")
            try:
                if image.mode in ('RGBA', 'P'): # Convert to RGB if necessary
                    image = image.convert('RGB')
                    print("Converted to RGB mode")
            except Exception as e:
                print(f"Error converting image format: {str(e)}")
                return f"Error converting image format: {str(e)}"
            
            print("Step 4: Resizing image if needed...")
            try:
                max_size = 768 # Example max size
                if max(image.size) > max_size:
                    ratio = max_size / max(image.size)
                    new_size = tuple(int(dim * ratio) for dim in image.size)
                    image = image.resize(new_size, Image.Resampling.LANCZOS) # Using LANCZOS for quality
                    print(f"Image resized to {new_size}")
            except Exception as e:
                print(f"Error resizing image: {str(e)}")
                return f"Error resizing image: {str(e)}"

            print("Step 5: Preparing for Gemini API to extract text...")
            gemini_ocr_prompt = """
            Task: Extract Halegannada (Old Kannada) text from this image.
            Instructions:
            1. Look for Halegannada text in the image.
            2. Return ONLY the extracted Halegannada text.
            3. Preserve any line breaks or formatting in the extracted text.
            If no Halegannada text is found, respond with "No Halegannada text detected in image"
            """

            if not gemini_model:
                return "Error: Gemini model not initialized."

            print("Step 6: Calling Gemini API for OCR...")
            try:
                img_byte_arr = BytesIO()
                # Determine image format; default to JPEG if not available or unsupported by PIL for saving
                save_format = image.format if image.format and image.format.upper() in ['JPEG', 'PNG', 'WEBP'] else 'JPEG'
                mime_type = f'image/{save_format.lower()}'
                
                image.save(img_byte_arr, format=save_format)
                img_byte_arr = img_byte_arr.getvalue()

                gemini_response = retry_with_backoff(
                    lambda: gemini_model.generate_content([
                        gemini_ocr_prompt,
                        {"mime_type": mime_type, "data": img_byte_arr}
                    ])
                )
                print("Received response from Gemini API for OCR")
                
                if not gemini_response or not hasattr(gemini_response, 'text'):
                    print("Error: Invalid or empty response from Gemini OCR")
                    return "Error: Could not extract text using Gemini"
                    
                extracted_text = gemini_response.text.strip()
                print(f"Text extracted by Gemini: {extracted_text[:200]}...")

                if not extracted_text or "No Halegannada text detected" in extracted_text:
                    return "No Halegannada text detected in image"
                
                print("Step 7: Translating extracted text using DeepSeek API...")
                english_translation = get_english_translation(extracted_text) # This now uses DeepSeek
                
                if "Translation error" in english_translation or "not available" in english_translation:
                    print(f"DeepSeek translation failed for extracted text: {english_translation}")
                    return "Error translating extracted text with DeepSeek"

                print(f"DeepSeek Translation successful. Result: {english_translation[:100]}...")
                return english_translation
                
            except Exception as e:
                print(f"Gemini API or subsequent DeepSeek call error: {str(e)}")
                traceback.print_exc()
                return f"Error during image processing pipeline: {str(e)}"

        except Exception as e: # Catches errors in image pre-processing
            print(f"Image pre-processing error: {str(e)}")
            traceback.print_exc()
            return f"Image pre-processing error: {str(e)}"

    except Exception as e: # Broadest catch for any unexpected error in process_image
        print("\n=== Error in process_image ===")
        print(f"Error: {str(e)}")
        traceback.print_exc()
        return f"Overall error in process_image: {str(e)}"

def get_kannada_translation(text):
    """Get Kannada translation from Dictionary.pkl by translating word by word."""
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        dictionary_path = os.path.join(current_dir, 'assets', 'Dictionary.pkl')
        
        if not os.path.exists(dictionary_path):
            print(f"Error: Dictionary.pkl not found at {dictionary_path}")
            return text
            
        with open(dictionary_path, 'rb') as f:
            meanings = pickle.load(f)

        # Translate word by word
        translated_words = [meanings.get(word, word) for word in text.split()]
        return ' '.join(translated_words)

    except Exception as e:
        print(f"Error loading dictionary or translating: {e}")
        traceback.print_exc()
        return text

def get_hosa_kannada_translation_api(text_to_translate):
    """Get Hosa Kannada translation using DeepSeek via OpenRouter API"""
    if not text_to_translate:
        return "No text provided for translation."
    print(f"Attempting OpenRouter (DeepSeek) translation to Hosa Kannada for: {text_to_translate[:100]}...")

    def _translate_with_openrouter_deepseek():
        try:
            response = deepseek_client.chat.completions.create(
                model="deepseek/deepseek-chat",
                messages=[
                    {"role": "system", "content": "You are an expert translator. Translate the given Halegannada (Old Kannada) text to modern, formal Hosa Kannada (Modern Kannada). Provide only the direct translation, without any extra explanations, commentary, or conversational filler."},
                    {"role": "user", "content": f"Translate the following Halegannada text to Hosa Kannada. Be brief and precise:\n\n{text_to_translate}"}
                ],
                stream=False,
                max_tokens=1000,
                temperature=0.5
            )
            if response.choices and response.choices[0].message and response.choices[0].message.content:
                translated_text = response.choices[0].message.content.strip()
                print("OpenRouter (DeepSeek) Hosa Kannada translation successful.")
                return translated_text
            else:
                print("OpenRouter (DeepSeek) API returned an empty or invalid response for Hosa Kannada translation.")
                return "Translation not available from OpenRouter (DeepSeek) (empty response)"
        except openai.APIError as e:
            print(f"OpenRouter (DeepSeek) APIError for Hosa Kannada translation: {e.status_code} - {e.message}")
            if e.status_code == 404 and "model_not_found" in str(e.code).lower():
                 print("Model 'deepseek/deepseek-chat' might be incorrect for OpenRouter. Please verify the model identifier on OpenRouter.")
                 return "Translation failed: Model not found on OpenRouter. Check model identifier."
            raise
        except Exception as e:
            print(f"Generic error during OpenRouter (DeepSeek) Hosa Kannada translation: {str(e)}")
            raise

    try:
        return retry_with_backoff(_translate_with_openrouter_deepseek)
    except Exception as e:
        error_message = f"OpenRouter (DeepSeek) Hosa Kannada translation error after retries: {str(e)}"
        print(error_message)
        if "Max retries" in str(e) and ("429" in str(e) or "quota" in str(e).lower()):
             return "Translation failed due to OpenRouter API rate limits after multiple retries."
        if "Model not found on OpenRouter" in str(e):
            return "Translation failed: Model not found on OpenRouter. Check model identifier."
        return f"Translation error: OpenRouter (DeepSeek) API unavailable or failed after retries."

def get_english_translation(text_to_translate):
    """Get English translation using DeepSeek via OpenRouter API"""
    if not text_to_translate:
        return "No text provided for translation."
    print(f"Attempting OpenRouter (DeepSeek) translation for: {text_to_translate[:100]}...")
    
    def _translate_with_openrouter_deepseek():
        try:
            response = deepseek_client.chat.completions.create(
                model="deepseek/deepseek-chat", 
                messages=[
                    {"role": "system", "content": "You are an expert translator. Translate the given text to English concisely and precisely. Provide only the direct translation, without any extra explanations, commentary, or conversational filler."},
                    {"role": "user", "content": f"Translate the following Halegannada (Old Kannada) or Modern Kannada text to English. Be brief and precise:\n\n{text_to_translate}"}
                ],
                stream=False,
                max_tokens=1000,  # Slightly reduced, but prompt is key
                temperature=0.5   # Lowered for more precise, less verbose output
            )
            if response.choices and response.choices[0].message and response.choices[0].message.content:
                translated_text = response.choices[0].message.content.strip()
                print("OpenRouter (DeepSeek) translation successful.")
                return translated_text
            else:
                print("OpenRouter (DeepSeek) API returned an empty or invalid response.")
                return "Translation not available from OpenRouter (DeepSeek) (empty response)"
        except openai.APIError as e:
            print(f"OpenRouter (DeepSeek) APIError: {e.status_code} - {e.message}")
            # Check for model not found error, which might indicate the model string is wrong for OpenRouter
            if e.status_code == 404 and "model_not_found" in str(e.code).lower():
                 print("Model 'deepseek/deepseek-chat' might be incorrect for OpenRouter. Please verify the model identifier on OpenRouter.")
                 # Return a more specific error message
                 return "Translation failed: Model not found on OpenRouter. Check model identifier."
            raise # Re-raise to be caught by retry_with_backoff
        except Exception as e:
            print(f"Generic error during OpenRouter (DeepSeek) translation: {str(e)}")
            raise # Re-raise to be caught by retry_with_backoff

    try:
        return retry_with_backoff(_translate_with_openrouter_deepseek)
    except Exception as e:
        error_message = f"OpenRouter (DeepSeek) translation error after retries: {str(e)}"
        print(error_message)
        if "Max retries" in str(e) and ("429" in str(e) or "quota" in str(e).lower()):
             return "Translation failed due to OpenRouter API rate limits after multiple retries."
        if "Model not found on OpenRouter" in str(e): # Propagate specific model not found error
            return "Translation failed: Model not found on OpenRouter. Check model identifier."
        return f"Translation error: OpenRouter (DeepSeek) API unavailable or failed after retries."

@app.route('/')
def index():
    return send_from_directory('.', 'index.html')

@app.route('/pages/<path:filename>')
def serve_pages(filename):
    return send_from_directory('pages', filename)

@app.route('/assets/<path:filename>')
def serve_assets(filename):
    return send_from_directory('assets', filename)

@app.route('/translate', methods=['POST'])
def translate():
    try:
        print("\n=== New Translation Request ===")
        data = request.json
        
        if not data:
            print("Error: No data received")
            return jsonify({'error': 'No data received', 'status': 'error'}), 400
            
        text_input = data.get('text', '')
        image_data = data.get('image', '')

        english_translation_result = ""
        kannada_translation_for_text_input = "" # Only for text input path

        if image_data:
            print("Image translation request received")
            english_translation_result = process_image(image_data)
            
            # Check for error messages from process_image
            if isinstance(english_translation_result, str) and any(err_keyword in english_translation_result.lower() for err_keyword in ['error', 'failed', 'not detected', 'unavailable']):
                status_code = 429 if "rate limit" in english_translation_result.lower() else 500
                return jsonify({
                    'error': english_translation_result,
                    'status': 'error',
                    'retry_after': INITIAL_RETRY_DELAY if status_code == 429 else None
                }), status_code
            
            print(f"Image translation completed. Final English result: {english_translation_result[:100]}...")
            return jsonify({
                'english': english_translation_result,
                'status': 'completed'
            })

        elif text_input:
            print(f"Text translation request received: {text_input}")
            source = data.get('source')
            
            # Get Kannada translation using the new API function
            if source == 'dictionary':
                kannada_translation_for_text_input = get_kannada_translation(text_input)
            else:
                kannada_translation_for_text_input = get_hosa_kannada_translation_api(text_input)

            # Get English translation
            english_translation_result = get_english_translation(text_input)

            print(f"Kannada Translation: {kannada_translation_for_text_input}")
            print(f"English Translation: {english_translation_result}")

            return jsonify({
                'kannada': kannada_translation_for_text_input,
                'english': english_translation_result,
                'status': 'completed'
            })
        else:
            return jsonify({'error': 'No text or image provided', 'status': 'error'}), 400
    
    except Exception as e:
        error_msg = f"General translation endpoint error: {str(e)}"
        print(error_msg)
        traceback.print_exc()
        return jsonify({
            'error': error_msg, 
            'status': 'error',
            'retry_after': INITIAL_RETRY_DELAY # Generic retry suggestion for unexpected server errors
        }), 500

def get_english_translation_seq2seq(text_input):
    """Translate Halegannada to English using the Seq2Seq model."""
    if not all([seq2seq_model, input_tokenizer, target_tokenizer]):
        print("Seq2Seq model or tokenizers are not available.")
        return None  # Return None to indicate fallback

    try:
        # Tokenize and pad the input text
        input_seq = input_tokenizer.texts_to_sequences([text_input])
        padded_input_seq = pad_sequences(input_seq, maxlen=max_input_len, padding='post')

        # Get model prediction
        prediction = seq2seq_model.predict(padded_input_seq)
        predicted_ids = np.argmax(prediction, axis=-1)

        # Detokenize the predicted sequence
        target_word_index = target_tokenizer.word_index
        reverse_target_word_index = {v: k for k, v in target_word_index.items()}

        translated_words = []
        for idx in predicted_ids[0]:
            if idx > 0:  # Ignore padding
                word = reverse_target_word_index.get(idx)
                if word:
                    if word == '<end>': # Stop at end token
                        break
                    translated_words.append(word)

        return ' '.join(translated_words)

    except Exception as e:
        print(f"Error during Seq2Seq translation: {str(e)}")
        traceback.print_exc()
        return None # Fallback on error


@app.route('/translate-halegannada', methods=['POST'])
def translate_halegannada():
    try:
        data = request.json
        text_input = data.get('text', '')
        if not text_input:
            return jsonify({'error': 'No text provided', 'status': 'error'}), 400

        # This endpoint is more specific, let's assume it might have different logic or models in the future.
        # For now, it will also use the dictionary for Kannada and DeepSeek for English.

        print(f"Halegannada translation request received: {text_input}")

        # Get Kannada translation using the new API function
        kannada_translation = get_hosa_kannada_translation_api(text_input)

        # Get English translation
        english_translation = get_english_translation(text_input)

        print(f"Kannada Translation: {kannada_translation}")
        print(f"English Translation: {english_translation}")

        return jsonify({
            'kannada_translation': kannada_translation,
            'english_translation': english_translation,
            'status': 'completed'
        })

    except Exception as e:
        error_msg = f"Halegannada translation endpoint error: {str(e)}"
        print(error_msg)
        traceback.print_exc()
        return jsonify({'error': error_msg, 'status': 'error'}), 500

if __name__ == '__main__':
    # Ensure the 'assets' directory exists, if not, create it.
    # This is mainly for the Dictionary.pkl, but good practice.
    if not os.path.exists('assets'):
        os.makedirs('assets')
        print("Created 'assets' directory as it was missing.")
    app.run(debug=True, port=5000) 